73
00:10:04,500 --> 00:10:14,240
For example, we can have a discrete valued
feature like whether it will rain or not tomorrow,

74
00:10:14,250 --> 00:10:23,620
such problems are called classification problems.
Or we can have a discrete valued feature which

75
00:10:23,620 --> 00:10:31,279
given the symptoms of the patient, predicts
whether a patient has a particular disease.

76
00:10:31,279 --> 00:10:38,670
Or you have continuous valued feature then
you call such problems regression.

77
00:10:38,670 --> 00:10:45,040
Suppose given the values of certain features
you want to predict the price of a house,

78
00:10:45,040 --> 00:10:50,820
so given the location of the house, the floor
area of the house, the number of bedrooms

79
00:10:50,820 --> 00:10:55,880
and some such features, you want to predict
the price of the house which is a continuous

80
00:10:55,880 --> 00:11:08,930
valued or real valued number and such problems
are called Regression problems.

81
00:11:08,930 --> 00:11:27,500
So, let us look at some examples of classification
problem. One example is Credit scoring. Suppose,

82
00:11:27,500 --> 00:11:35,320
in this problem we are describing each input
in terms of two features; income and savings.

83
00:11:35,320 --> 00:11:41,199
We have a person, we look at the income and
the savings of a person and we want to predict

84
00:11:41,199 --> 00:11:47,160
whether this is a high risk person or a low
risk person. And you seeing this picture,

85
00:11:47,160 --> 00:11:55,649
the high risk persons are labeled with minus
and the low risk persons labeled with plus.

86
00:11:55,649 --> 00:12:02,160
Now given this data you want to come up with
a classifier which given the attributes of

87
00:12:02,160 --> 00:12:10,111
a new person will predict whether that person
is high risk or low risk. And this is an example

88
00:12:10,111 --> 00:12:16,440
of a rule that you have found if income is
greater than theta 1 and savings is greater

89
00:12:16,440 --> 00:12:23,209
than theta 2 then the person is low risk else
the person is high risk. This rule you have

90
00:12:23,209 --> 00:12:30,009
come up with the rule based on the data. In
this case you can visualize the data and come

91
00:12:30,009 --> 00:12:31,129
up with the rule.

92
00:12:33,290 --> 00:12:38,139
Now let us look at an example of a regression
problem. You want to find out the price of

93
00:12:38,139 --> 00:12:45,199
a used car and you use certain attributes
of the car to predict its price. For example,

94
00:12:45,199 --> 00:12:49,980
let us say that you have only looking at the
mileage of the car and based on the mileage

95
00:12:49,980 --> 00:12:58,980
you have predicting the price. And these different
points they correspond to a particular car

96
00:12:58,980 --> 00:13:02,100
show what is the mileage and what is the corresponding
price.

97
00:13:02,650 --> 00:13:08,470
So given the mileage price of several cars
you have the data points and you can come

98
00:13:08,470 --> 00:13:16,389
up with the function so that given a new car
whose mileage is given you can predict the

99
00:13:16,389 --> 00:13:26,750
price. In regression you come up with a function
which takes the input instance and the parameters

100
00:13:26,750 --> 00:13:27,510
of the model.

101
00:13:29,580 --> 00:13:39,040
Now, we see that in order to describe an instance
features play a very important role. Observations

102
00:13:39,040 --> 00:13:44,769
that you see are analyzed into a set of quantifiable
properties which are called features. So if

103
00:13:44,769 --> 00:13:50,819
you want to predict the price of a car or
the price of a house you have to have the

104
00:13:50,819 --> 00:13:55,720
right features which will help you to come
up with the price. If you want to predict

105
00:13:55,720 --> 00:14:01,430
what disease a patient has you have to come
up with the right tests and parameters which

106
00:14:01,430 --> 00:14:06,541
will enable you to make that prediction.
Now feature are of various types. Features

107
00:14:06,541 --> 00:14:12,459
can be categorical. For example, blood group
is a feature which has four values “A”,

108
00:14:12,459 --> 00:14:18,579
“B”, “AB” and “O”, or gender is
feature which has certain values like, male,

109
00:14:18,579 --> 00:14:25,370
female etcetera. Or features can ordinal like,
large, medium, small. Features can be integer

110
00:14:25,370 --> 00:14:32,280
valued like, the number of words in a text
or a feature can be real valued like height.

111
00:14:32,280 --> 00:14:40,080
Now, let us look at this table which shows
a sample training examples and for these training

112
00:14:40,080 --> 00:14:47,639
examples you have five features; action, author,
thread, length, where. And the different rows

113
00:14:47,639 --> 00:14:54,680
are the different instances. So instance e
1 says; action is skips, author is known,

114
00:14:54,680 --> 00:15:02,870
thread is new, length is long, and the person
is at home. These are the different instances