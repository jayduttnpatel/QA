147
00:20:06,840 --> 00:20:16,119
Now, it is not possible in real time to find
out the most similar users because as we have

148
00:20:16,119 --> 00:20:21,070
seen instance based learning algorithms. So,
this types of learning algorithms are lazy

149
00:20:21,070 --> 00:20:27,229
at run time you find the most similar users
and if the total number of users very large

150
00:20:27,229 --> 00:20:33,669
it is difficult without the use of good data
structures to find the most similar users

151
00:20:33,669 --> 00:20:40,669
in runtime and while several data structures,
clustering etcetera can be used to make this

152
00:20:40,669 --> 00:20:48,489
more efficient and alternative to user based
nearest neighbor is item based nearest neighbor

153
00:20:48,489 --> 00:20:51,189
or item based collaborative, filtering

154
00:21:00,960 --> 00:21:08,550
in item based collaborative filtering, what
we do is that we find similarity between the

155
00:21:08,550 --> 00:21:10,430
items we compare the items.

156
00:21:15,920 --> 00:21:19,260
So, if you two items i and j.

157
00:21:20,220 --> 00:21:28,059
The similarities between these two items are
computed as the formula is very similar to

158
00:21:28,059 --> 00:21:35,759
what we used for user based collaborative
filtering. Here, we sum over all users, we

159
00:21:35,759 --> 00:22:01,220
look at r u i minus r u bar times r u j minus
r u bar. So, we look at the rating of user

160
00:22:01,220 --> 00:22:09,759
u for item i times the rating of user u for
item j and again we use the normalization

161
00:22:09,759 --> 00:22:20,539
we subtract the mean for that user and in
the denominator, we have root over sigma over

162
00:22:20,539 --> 00:22:40,959
all users r u i minus r u bar whole square
times sigma over all users r u j minus r u

163
00:22:40,960 --> 00:22:50,780
bar whole square right. So, based on this
we find the similarity between the items.

164
00:22:51,139 --> 00:22:54,219
Now, once we find a similarity of the items

165
00:22:54,849 --> 00:23:00,809
in the neighborhood formation phase then we
go to the recommendation phase. In the recommendation

166
00:23:00,809 --> 00:23:08,070
phase, we select a set of k most similar items
to the target items. So, we have a target

167
00:23:08,070 --> 00:23:14,940
item i and for the target item we find the
most similar items.

168
00:23:14,940 --> 00:23:28,370
So, target item is i. We find the k most similar
items i 1, i 2, i k based on this formula

169
00:23:28,370 --> 00:23:38,190
that we have written right and then we do
the rating prediction. The rating prediction

170
00:23:38,190 --> 00:23:53,419
is done p u i as sigma i take the summation
over the similar items capital j are the k

171
00:23:53,419 --> 00:24:11,279
similar items we do r u j times the similarity
of item, i item j divided by sigma j again

172
00:24:11,279 --> 00:24:28,729
over all neighboring items sim i j.
So, based on this the rating is predicted,

173
00:24:28,729 --> 00:24:36,849
this item based collaborative filtering. So,
with this brief introduction we come to the

174
00:24:36,849 --> 00:24:42,159
end of our recommendation systems, which is
an application of k-nearest neighbors and

175
00:24:42,159 --> 00:24:50,940
we also come to an end of this module after
this the next module that we start is on probabilities

176
00:24:50,940 --> 00:24:57,729
Bayesian learning, naive bayes and few such
things of course, we will also have one class

177
00:24:57,729 --> 00:25:07,549
by our teaching assistant on how to use this
nearest neighbor and instance based learning

178
00:25:07,549 --> 00:25:11,090
type of algorithms in some application.
Thank you very much.