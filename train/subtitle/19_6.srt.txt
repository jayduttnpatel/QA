190
00:25:04,509 --> 00:25:09,960
results.
But, we cannot always apply Naive Bayes. And

191
00:25:09,960 --> 00:25:18,190
as we have seen, we cannot do the full joint
distribution. Probability X 1 X n given Y,

192
00:25:18,190 --> 00:25:29,859
it is not tractable to really do this. And
to alleviate this, we study Bayesian networks.

193
00:25:29,859 --> 00:25:40,159
In Bayesian networks, we can strike a balance;
we need not make full independence assumptions

194
00:25:40,159 --> 00:25:52,640
or full dependent assumptions, rather we denote
the causal relationships and conditional independence.

195
00:25:52,640 --> 00:26:00,270
The specific conditional independence of the
different attributes; and in belief networks,

196
00:26:00,270 --> 00:26:11,450
we also denote causal relationships. So, we
show the actual relations and actual independences

197
00:26:11,450 --> 00:26:22,559
between the attributes. And based on this
we can get different learning algorithms,

198
00:26:22,559 --> 00:26:29,179
which I have do not make as Naive assumptions
as Naive Bayes, but can capture the relationships

199
00:26:29,179 --> 00:26:35,070
in the domain.
And it is an advanced topic, and we have different

200
00:26:35,070 --> 00:26:48,260
types of the Bayesian networks; we have belief
networks also called Directed graphical model.

201
00:26:48,260 --> 00:26:56,580
We also have another type of networks â€“ Bayesian
networks, which are called Undirected graphical

202
00:26:56,580 --> 00:27:03,720
models. And these can capture different relationships.
But today we finish this topic.

203
00:27:03,720 --> 00:27:06,029
Thank you very much.