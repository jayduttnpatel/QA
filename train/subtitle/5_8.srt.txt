305
00:34:59,099 --> 00:35:06,519
of symptoms may appear within you know image
that has been presented to it to the learning

306
00:35:06,519 --> 00:35:11,529
algorithm to the machine that you trained.

307
00:35:11,529 --> 00:35:17,809
And it may mesh things are because this particular
set of symptoms which is really rare, did

308
00:35:17,809 --> 00:35:22,789
not appear in the training example set, so
that is why it will fail in that particular

309
00:35:22,789 --> 00:35:23,950
scenario.

310
00:35:23,950 --> 00:35:32,789
So, what is going to happen in the real world,
when the system is really deployed is what

311
00:35:32,789 --> 00:35:39,700
really matters and that is why that is what
we mean by generalization performance.

312
00:35:39,700 --> 00:35:47,049
So, you have a certain training error, but
and that is say we say the let us assume that

313
00:35:47,049 --> 00:35:51,030
that training error is really small and so
you are confident that yeah your system is

314
00:35:51,030 --> 00:35:55,039
performing really great on your training set.

315
00:35:55,039 --> 00:36:00,519
But to get an idea about how good it would
perform in the real world when it is really

316
00:36:00,519 --> 00:36:04,089
deployed, you have to go and check the generalization
performance of the learning algorithm.

317
00:36:04,089 --> 00:36:08,690
So, the generalization performance of the
learning algorithm can be controlled by controlling

318
00:36:08,690 --> 00:36:13,170
the bias and variance of the algorithm and
that is what you will be taught in the rest

319
00:36:13,170 --> 00:36:14,219
of the course, as we go along.

320
00:36:14,219 --> 00:36:19,700
We study one model after another, and we will
check, we will study how to control the generalization

321
00:36:19,700 --> 00:36:22,789
performance by controlling the amount of bias
or variance.

322
00:36:22,789 --> 00:36:27,650
And, but how to check the generalization performance,
so that is why whenever we have been given

323
00:36:27,650 --> 00:36:40,219
a big data set, we make you know what do we
do we just randomly select a particular section

324
00:36:40,219 --> 00:36:42,859
of the dataset and we keep it aside.

325
00:36:42,859 --> 00:36:48,759
So, keep it aside as test data.

326
00:36:48,759 --> 00:36:55,640
So, we buy we buy no means are going to show
the algorithm, this particular part of the

327
00:36:55,640 --> 00:36:57,049
dataset that has been given to us.

328
00:36:57,049 --> 00:37:02,249
So, this particular set of examples will be
unseen to the learning algorithm to our machine

329
00:37:02,249 --> 00:37:09,499
while it is getting trained, and the remaining
dataset what we have, so we are going to split

330
00:37:09,499 --> 00:37:19,260
it again into a validation set and the training
set.

331
00:37:19,260 --> 00:37:30,940
So, the training set is what is used for machine
learning for training the machine rather I

332
00:37:30,940 --> 00:37:37,079
would say that this goes to train the machine.

333
00:37:37,079 --> 00:37:45,890
So, say after a certain period of training,
so say you are doing some like may be 30 rounds

334
00:37:45,890 --> 00:37:50,759
or 50 rounds of training, you are showing
the training examples is getting out giving outputs

335
00:37:51,759 --> 00:37:54,829
So, you are checking the amount of error that
has been incurred in that particular episode

336
00:37:54,829 --> 00:37:58,349
and then you are trying to reduce the error
by gradient descent or some other algorithm.

337
00:37:58,460 --> 00:38:03,880
So, after training the machine for sometimes
you want to go ahead and check that how good

338
00:38:03,880 --> 00:38:05,289
the machine is generalizing.

339
00:38:05,289 --> 00:38:10,650
So, this validation set was held out, so it
was not being shown to the machine while being

340
00:38:10,650 --> 00:38:13,180
trained so you will be just going to train
it on the training set.

341
00:38:13,180 --> 00:38:21,239
And then this validation set comes in and
evaluates generalization.

342
00:38:21,239 --> 00:38:31,760
So, you check how good how the machine is
performing on the validation set.

343
00:38:31,760 --> 00:38:37,979
So, if you see that the validation error is
quite high, while the training error was low

344
00:38:37,979 --> 00:38:41,849
you can say that yeah the machine is not generalizing,
my machine is not generalizing, so I need

345
00:38:41,849 --> 00:38:43,910
to check the learning algorithm.

346
00:38:43,910 --> 00:38:48,640
I must you know train it all over again, because
when you are showing some data that it has

347
00:38:48,640 --> 00:38:52,609
not seen in the training examples, then its
messing things up.

348
00:38:52,609 --> 00:38:59,760
So, we go like in the entire process of training
at regular intervals of time, we stop the

349
00:38:59,760 --> 00:39:02,829
training of the machine and then checks his
performance on the validation set.

350
00:39:02,829 --> 00:39:07,989
And this gives us a measure of how well the
system is generalizing.

351
00:39:07,989 --> 00:39:11,269
Now this way we train the machine.

352
00:39:11,959 --> 00:39:16,579
So, we started from a randomly initialized
machine, we trained it on the training set,

353
00:39:16,579 --> 00:39:22,779
and periodically you know evaluated on the
validation set and finally, we have a machine

354
00:39:22,779 --> 00:39:26,319
which has low training error as well as low
validation error.

355
00:39:26,319 --> 00:39:31,569
So, I have a little bit of confidence that
yeah the machine is has learned the problem

356
00:39:31,569 --> 00:39:38,130
very well and so it is having a small amount
of training error, also it is generalizing

357
00:39:38,130 --> 00:39:41,150
quite well because it has a small amount of
validation error as well.

358
00:39:41,410 --> 00:39:49,499
Now, as of first now you must be careful to
notice that this validation data validation

359
00:39:49,499 --> 00:39:54,329
set was not use for training the system, but
it was used to evaluate the system while it

360
00:39:54,329 --> 00:39:55,169
was getting trained.

361
00:39:55,940 --> 00:40:03,890
So on the basis of the validation set results;
we were going and tuning the learning algorithm,