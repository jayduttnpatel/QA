133
00:14:59,890 --> 00:15:05,410
then this product becomes a sum and that makes
our life simpler.

134
00:15:05,650 --> 00:15:13,100
So, now we go ahead and calculate the class
posteriors. For calculating the class posteriors

135
00:15:13,100 --> 00:15:24,460
we again show the feature vector, the binary
vector that we talked about representing which

136
00:15:24,460 --> 00:15:29,260
particular feature is present or absent or
which particular word is present or absent.

137
00:15:30,020 --> 00:15:40,470
And then the log posterior of each class will
be the sum of the log prior and the log likelihood,

138
00:15:40,470 --> 00:15:45,930
and we return them. Another function classifies
spam it takes document vectors, so the document

139
00:15:45,930 --> 00:15:55,360
vector is the one that was presented originally
in the data set which give the relative frequencies

140
00:15:55,360 --> 00:15:58,850
of the words.
So, we just going to check whether the element

141
00:15:58,850 --> 00:16:03,540
was greater than 0 in that particular vector,
and if it is going to be greater than 0 this

142
00:16:03,540 --> 00:16:08,860
means the word appeared in the particular
email and that is why we just said that element

143
00:16:08,860 --> 00:16:14,360
will equal to 1. This is what it does. It
converted into a feature vector and then we

144
00:16:14,360 --> 00:16:23,560
calculate the log posteriors using this function.
And we return class 0, that is not a spam

145
00:16:23,560 --> 00:16:28,740
if the aposteriori probability of not a spam
be greater than aposteriori probability of

146
00:16:28,740 --> 00:16:35,720
it being a spam email otherwise we classify
it as a spam email. So, this is how we solve

147
00:16:35,720 --> 00:16:41,720
the problem, how we use naive bayes classifier
for detection of spam.

148
00:16:42,840 --> 00:16:51,910
And, evaluation shows that it gives 89.23
percent classification accuracy and that is

149
00:16:51,910 --> 00:17:07,510
quite compiling. And this function will check
how many of the predictions match the ground

150
00:17:07,510 --> 00:17:13,360
truth labels. So, it is checking whether the
predictions are same as the ground truth and

151
00:17:13,360 --> 00:17:24,740
it calculates the accuracy. You just print
the value, and thus you can use naive bayes

152
00:17:24,740 --> 00:17:28,180
algorithm for classifying emails as spam on
non spam.

153
00:17:28,889 --> 00:17:33,499
So, I hope that was enjoyable. See you in
the next video, bye-bye.