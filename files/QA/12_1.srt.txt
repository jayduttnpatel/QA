1
00:00:18,810 --> 00:00:26,590
Good morning. Today we will start module 3.
In this module, we will talk about instance

2
00:00:27,000 --> 00:00:34,460
based learning and then, we will talk about
feature selection, will show instance base

3
00:00:34,460 --> 00:00:41,100
learning feature. Dimensionality is a problem
and feature large having many features is

4
00:00:41,100 --> 00:00:46,200
a problem for many other learning algorithms
and we will look for methods for feature selection.

5
00:00:46,610 --> 00:00:52,260
In the first part of the lecture which we
will have today, we will talk about instance

6
00:00:52,260 --> 00:01:00,600
base learning and specially the k nearest
neighbor algorithm. So, what we have is that

7
00:01:00,600 --> 00:01:07,780
suppose in the machine learning in supervise
learning, you have got training examples x y

8
00:01:08,340 --> 00:01:19,229
A set of them x i, y i or you can say x i,
f x i. So, these examples are given to you

9
00:01:19,229 --> 00:01:25,859
and given these examples, you want to come
up with the function f and you want to find

10
00:01:25,859 --> 00:01:34,579
an estimate for the function f. In the previous
module, we have seen how to learn linear regression,

11
00:01:34,579 --> 00:01:41,569
a linear function f or a decision tree, a
function which is a decision tree to estimate

12
00:01:41,569 --> 00:01:46,819
this f.
Today we will look at another setting called

13
00:01:46,819 --> 00:01:55,069
instance based learning, also called lazy
learning. I mean the algorithm that we will

14
00:01:55,069 --> 00:02:03,219
discuss is a lazy algorithm; we will tell
what it means. Instance based learning what

15
00:02:03,219 --> 00:02:12,420
we do is that when we get the training examples,
we do not process them and learn a model instead.

16
00:02:12,420 --> 00:02:19,830
We just store the examples. When we need to
classify an instance that time we do something.

17
00:02:19,830 --> 00:02:25,810
So, we do not immediately learn a model that
is why the algorithm that we will discuss

18
00:02:25,810 --> 00:02:34,510
is also called a lazy algorithm that is the
algorithm does not come up with the model

19
00:02:34,510 --> 00:02:42,849
apiary rather when it gets the test instance,
it uses the stored instance in memory in order

20
00:02:42,849 --> 00:02:50,069
to find the possible y.
So, how does it do it? Suppose this is the

21
00:02:50,069 --> 00:02:56,770
instance phase and you have different points
in the instance phase. For each point, you

22
00:02:56,770 --> 00:03:07,459
have the corresponding x value and the y value.
When you are given a new instance, you find

23
00:03:07,459 --> 00:03:16,200
what the closest instance in terms of the
x value is and suppose this is the closest

24
00:03:16,200 --> 00:03:21,819
you would find the y value of the instance
and you guess the y value of this as the y

25
00:03:21,819 --> 00:03:30,349
value of this. This is the basic nearest neighbor
algorithm. Now, in order to do this given

26
00:03:30,349 --> 00:03:49,469
a test instance, you have to find similar
instance. So, you want to find most similar

27
00:03:49,469 --> 00:03:57,430
instance or we will see in some cases, we
want to find some neighboring instance, the

28
00:03:57,430 --> 00:04:04,659
most the nearest instances.
Now, how to find the similarity or what is

29
00:04:04,659 --> 00:04:10,299
the distance function at the metric that we
consider. For similarity we can use a standard

30
00:04:10,299 --> 00:04:16,260
metric like. Secondly, distance or other metrics
like cosine and other depending on the type

31
00:04:16,260 --> 00:04:23,410
of data that you are looking for. So, the
basic k nearest neighbor algorithm, the algorithm

32
00:04:23,410 --> 00:04:31,720
that I am going to describe is called the
k nearest neighbor algorithm and let us out

33
00:04:31,720 --> 00:04:32,880
line that algorithm.

34
00:04:52,100 --> 00:04:57,080
So, the k nearest neighbor works as follows.
As we have seen earlier learning algorithm

35
00:04:57,090 --> 00:05:03,190
has two phases; training phase and testing
phase or the use phase. So, in the training